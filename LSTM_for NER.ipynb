{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "pd.set_option('chained_assignment',None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.txt',sep = \" \",skip_blank_lines=False,skiprows=[1])\n",
    "val_df = pd.read_csv('valid.txt',sep = \" \",skip_blank_lines=False,skiprows=[1])\n",
    "test_df = pd.read_csv('test.txt',sep = \" \",skip_blank_lines=False,skiprows=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareData(object):\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "\n",
    "    def preprocess_dataset(self):\n",
    "        self.df = self.df.rename({\"-DOCSTART-\": \"Word\", \"-X-\": \"POS\", \"-X-.1\": \"Chunk\", \"O\": \"NER_tag\"}, axis=1)\n",
    "        indexes_to_drop = self.df.loc[self.df[\"Word\"] == \"-DOCSTART-\"].index.tolist()\n",
    "        # df = df.drop(indexes_to_drop,axis = 0 )\n",
    "        empty_word_cells = self.df.loc[self.df[\"Word\"] == \" \"].index.tolist()\n",
    "        #none_word_cells = self.df.loc[self.df[\"Word\"].isnull()].index.tolist()\n",
    "        indexes_to_drop.extend([i + 1 for i in indexes_to_drop])\n",
    "        indexes_to_drop.extend(empty_word_cells)\n",
    "        #indexes_to_drop.extend(none_word_cells)\n",
    "        indexes_to_drop.sort()\n",
    "        self.df = self.df.drop(indexes_to_drop, axis=0)\n",
    "        #print(\"Null words if any still existing:\" + \" \" + str(len(self.df.loc[self.df[\"Word\"] == \" \"].index)))\n",
    "        self.df = self.df.reset_index()\n",
    "        self.df.drop([\"index\"], axis=1, inplace=True)\n",
    "        sent_range = np.where(self.df.isnull().sum(axis=1).to_frame()[0] == 4)[0].tolist()\n",
    "        self.df[\"sent_id\"] = \"\"\n",
    "        for index, value in enumerate(sent_range):\n",
    "            if index == 0:\n",
    "                self.df[\"sent_id\"][index:value] = str(index)\n",
    "            else:\n",
    "                self.df[\"sent_id\"][sent_range[index - 1] + 1:sent_range[index]] = str(index)\n",
    "        self.df.drop(np.where(self.df.isnull().sum(axis=1).to_frame()[0] == 4)[0].tolist(), inplace=True)\n",
    "        self.df.reset_index(inplace=True)\n",
    "        self.df.drop([\"index\"], inplace=True, axis=1)\n",
    "        return self.df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data = PrepareData(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = prepare_data.preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_val_data = PrepareData(val_df)\n",
    "val_df = prepare_val_data.preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_test_data = PrepareData(test_df)\n",
    "test_df = prepare_test_data.preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional cleaning for NaN words\n",
    "none_word_cells = train_df.loc[train_df[\"Word\"].isnull()].index.tolist()\n",
    "train_df.fillna(\"None\",inplace = True)\n",
    "val_df.fillna(\"None\",inplace = True)\n",
    "test_df.fillna(\"None\",inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.n_sent = 1\n",
    "        self.dataset = dataset\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                        s[\"NER_tag\"].values.tolist())]\n",
    "        self.grouped = self.dataset.groupby(\"sent_id\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(train_df)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 113\n"
     ]
    }
   ],
   "source": [
    "maxlen = max([len(s) for s in sentences])\n",
    "print ('Maximum sequence length:', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(train_df[\"Word\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23621"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set(train_df[\"NER_tag\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pad_sequences(maxlen=113, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 6, 1, ..., 6, 6, 6],\n",
       "       [0, 8, 6, ..., 6, 6, 6],\n",
       "       [1, 6, 6, ..., 6, 6, 6],\n",
       "       ...,\n",
       "       [6, 0, 8, ..., 6, 6, 6],\n",
       "       [6, 0, 8, ..., 6, 6, 6],\n",
       "       [6, 6, 6, ..., 6, 6, 6]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
