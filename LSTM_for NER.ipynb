{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras_metrics\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras.utils import to_categorical\n",
    "pd.set_option('chained_assignment',None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "train_df = pd.read_csv('train.txt',sep = \" \",skip_blank_lines=False,skiprows=[1])\n",
    "val_df = pd.read_csv('valid.txt',sep = \" \",skip_blank_lines=False,skiprows=[1])\n",
    "test_df = pd.read_csv('test.txt',sep = \" \",skip_blank_lines=False,skiprows=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to clean and index the dataset\n",
    "class PrepareData(object):\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "\n",
    "    def preprocess_dataset(self):\n",
    "        self.df = self.df.rename({\"-DOCSTART-\": \"Word\", \"-X-\": \"POS\", \"-X-.1\": \"Chunk\", \"O\": \"NER_tag\"}, axis=1)\n",
    "        indexes_to_drop = self.df.loc[self.df[\"Word\"] == \"-DOCSTART-\"].index.tolist()\n",
    "        # df = df.drop(indexes_to_drop,axis = 0 )\n",
    "        empty_word_cells = self.df.loc[self.df[\"Word\"] == \" \"].index.tolist()\n",
    "        #none_word_cells = self.df.loc[self.df[\"Word\"].isnull()].index.tolist()\n",
    "        indexes_to_drop.extend([i + 1 for i in indexes_to_drop])\n",
    "        indexes_to_drop.extend(empty_word_cells)\n",
    "        #indexes_to_drop.extend(none_word_cells)\n",
    "        indexes_to_drop.sort()\n",
    "        self.df = self.df.drop(indexes_to_drop, axis=0)\n",
    "        #print(\"Null words if any still existing:\" + \" \" + str(len(self.df.loc[self.df[\"Word\"] == \" \"].index)))\n",
    "        self.df = self.df.reset_index()\n",
    "        self.df.drop([\"index\"], axis=1, inplace=True)\n",
    "        sent_range = np.where(self.df.isnull().sum(axis=1).to_frame()[0] == 4)[0].tolist()\n",
    "        self.df[\"sent_id\"] = \"\"\n",
    "        for index, value in enumerate(sent_range):\n",
    "            if index == 0:\n",
    "                self.df[\"sent_id\"][index:value] = str(index)\n",
    "            else:\n",
    "                self.df[\"sent_id\"][sent_range[index - 1] + 1:sent_range[index]] = str(index)\n",
    "        self.df.drop(np.where(self.df.isnull().sum(axis=1).to_frame()[0] == 4)[0].tolist(), inplace=True)\n",
    "        self.df.reset_index(inplace=True)\n",
    "        self.df.drop([\"index\"], inplace=True, axis=1)\n",
    "        return self.df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the function on all three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data = PrepareData(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = prepare_data.preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_val_data = PrepareData(val_df)\n",
    "val_df = prepare_val_data.preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_test_data = PrepareData(test_df)\n",
    "test_df = prepare_test_data.preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional cleaning for NaN words\n",
    "none_word_cells = train_df.loc[train_df[\"Word\"].isnull()].index.tolist()\n",
    "train_df.fillna(\"None\",inplace = True)\n",
    "val_df.fillna(\"None\",inplace = True)\n",
    "test_df.fillna(\"None\",inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighting_df = train_df[\"NER_tag\"].value_counts().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_all_classes = weighting_df[\"NER_tag\"].sum()\n",
    "weighting_df[\"percentage\"] = 1 - (weighting_df[\"NER_tag\"]/sum_of_all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>NER_tag</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>167400</td>\n",
       "      <td>0.168996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>7140</td>\n",
       "      <td>0.964556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>6600</td>\n",
       "      <td>0.967236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>6321</td>\n",
       "      <td>0.968621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>4528</td>\n",
       "      <td>0.977522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>3704</td>\n",
       "      <td>0.981613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B-MISC</td>\n",
       "      <td>3438</td>\n",
       "      <td>0.982933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I-LOC</td>\n",
       "      <td>1157</td>\n",
       "      <td>0.994256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-MISC</td>\n",
       "      <td>1155</td>\n",
       "      <td>0.994266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  NER_tag  percentage\n",
       "0       O   167400    0.168996\n",
       "1   B-LOC     7140    0.964556\n",
       "2   B-PER     6600    0.967236\n",
       "3   B-ORG     6321    0.968621\n",
       "4   I-PER     4528    0.977522\n",
       "5   I-ORG     3704    0.981613\n",
       "6  B-MISC     3438    0.982933\n",
       "7   I-LOC     1157    0.994256\n",
       "8  I-MISC     1155    0.994266"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to get sentences as sentences will be fed to the lstm\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.n_sent = 1\n",
    "        self.dataset = dataset\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                        s[\"NER_tag\"].values.tolist())]\n",
    "        self.grouped = self.dataset.groupby(\"sent_id\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting sentences for all 3 datasets\n",
    "getter = SentenceGetter(train_df)\n",
    "sentences = getter.sentences\n",
    "getter_val = SentenceGetter(val_df)\n",
    "val_sentences = getter_val.sentences\n",
    "getter_test = SentenceGetter(test_df)\n",
    "test_sentences = getter_test.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length for train,val,test: 113   109   124\n"
     ]
    }
   ],
   "source": [
    "# checking max length \n",
    "maxlen = max([len(s) for s in sentences])\n",
    "maxlen_val = max([len(s) for s in val_sentences])\n",
    "maxlen_test = max([len(s) for s in test_sentences])\n",
    "print ('Maximum sequence length for train,val,test:', maxlen , \" \" ,maxlen_val ,\" \", maxlen_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(train_df[\"Word\"].values))\n",
    "words_val = list(set(val_df[\"Word\"].values))\n",
    "words_test = list(set(test_df[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "words_val.append('ENDPAD')\n",
    "words_test.append('ENDPAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Length of all words\n",
    "n_words = len(words)\n",
    "n_words_val = len(words_val)\n",
    "n_words_test = len(words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all distinct tags\n",
    "tags = list(set(train_df[\"NER_tag\"].values))\n",
    "tags_val = list(set(val_df[\"NER_tag\"].values))\n",
    "tags_test = list(set(test_df[\"NER_tag\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tags = len(tags)\n",
    "n_tags_val = len(tags_val)\n",
    "n_tags_test = len(tags_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to numerical representation of words and tags\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "word2idx_val = {w: i for i, w in enumerate(words_val)}\n",
    "tag2idx_val = {t: i for i, t in enumerate(tags_val)}\n",
    "word2idx_test = {w: i for i, w in enumerate(words_test)}\n",
    "tag2idx_test = {t: i for i, t in enumerate(tags_test)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the words in the dataset to numbers for each sentence\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X_val = [[word2idx_val[w[0]] for w in s] for s in val_sentences]\n",
    "X_test = [[word2idx_test[w[0]] for w in s] for s in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the tags in the dataset to numbers for each sentence\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y_val = [[tag2idx_val[w[1]] for w in s] for s in val_sentences]\n",
    "y_test = [[tag2idx_test[w[1]] for w in s] for s in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding with a fixed length for words . The pad value is \"ENDPAD\"\n",
    "X = pad_sequences(maxlen=130, sequences=X, padding=\"post\",value=n_words - 1)\n",
    "X_val = pad_sequences(maxlen=130, sequences=X_val, padding=\"post\",value=n_words_val - 1)\n",
    "X_test = pad_sequences(maxlen=130, sequences=X_test, padding=\"post\",value=n_words_test - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a class weight dictionary for imbalanced dataset\n",
    "#weight_dict = dict()\n",
    "#for key,value in tag2idx.items():\n",
    "#    per = weighting_df[\"percentage\"].loc[weighting_df[\"index\"] == key].item()\n",
    "#    weight_dict[value] = per\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding with a fixed length for words . The pad value is \"O\"\n",
    "y = pad_sequences(maxlen=130, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "y_val = pad_sequences(maxlen=130, sequences=y_val, padding=\"post\", value=tag2idx_val[\"O\"])\n",
    "y_test = pad_sequences(maxlen=130, sequences=y_test, padding=\"post\", value=tag2idx_test[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing y to one hot encoding type\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "y_val = [to_categorical(i, num_classes=n_tags_val) for i in y_val]\n",
    "y_test = [to_categorical(i, num_classes=n_tags_test) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating LSTM model\n",
    "input = Input(shape=(130,))\n",
    "model = Embedding(input_dim=n_words, output_dim=130, input_length=130)(input)\n",
    "model = Dropout(0.1)(model)\n",
    "model = (LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)\n",
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\",keras_metrics.f1_score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "14039/14039 [==============================] - 100s 7ms/step - loss: 0.1103 - acc: 0.9814 - f1_score: 0.0000e+00\n",
      "Epoch 2/3\n",
      "14039/14039 [==============================] - 106s 8ms/step - loss: 0.0340 - acc: 0.9891 - f1_score: 0.0224\n",
      "Epoch 3/3\n",
      "14039/14039 [==============================] - 109s 8ms/step - loss: 0.0200 - acc: 0.9950 - f1_score: 0.5418\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, np.array(y), batch_size=24, epochs=3,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(np.array(X_test))\n",
    "p = np.argmax(prediction, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
